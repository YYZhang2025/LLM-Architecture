_wandb:
    value:
        cli_version: 0.21.3
        e:
            plgowdnbcpu9vb4wdz48wfsunn1adx9h:
                apple:
                    ecpuCores: 4
                    gpuCores: 20
                    memoryGb: 48
                    name: Apple M4 Pro
                    pcpuCores: 10
                    ramTotalBytes: "51539607552"
                    swapTotalBytes: "5368709120"
                codePath: train_scripts/train_baseline.py
                codePathLocal: train_scripts/train_baseline.py
                cpu_count: 14
                cpu_count_logical: 14
                disk:
                    /:
                        total: "494384795648"
                        used: "215440470016"
                email: yuyangzhang2025@gmail.com
                executable: /Users/yuyang/Desktop/Projects/LLM-Architecture/.venv/bin/python
                git:
                    commit: 429fd9ee72d9e8d00b4c83412c29a73ce1874f28
                    remote: git@github.com:YYZhang2025/LLM-Architecture.git
                host: YuyangZhangs-MacBook-Pro.local
                memory:
                    total: "51539607552"
                os: macOS-15.6-arm64-arm-64bit
                program: /Users/yuyang/Desktop/Projects/LLM-Architecture/train_scripts/train_baseline.py
                python: CPython 3.12.11
                root: /Users/yuyang/Desktop/Projects/LLM-Architecture
                startedAt: "2025-09-04T08:45:40.521740Z"
                writerId: plgowdnbcpu9vb4wdz48wfsunn1adx9h
        m: []
        python_version: 3.12.11
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 13
                - 16
                - 61
            "4": 3.12.11
            "5": 0.21.3
            "12": 0.21.3
            "13": darwin-arm64
model_cfg:
    value:
        d_ff: 2048
        d_model: 512
        max_seq_len: 512
        n_heads: 8
        n_layers: 6
        vocab_size: 16000
train_cfg:
    value:
        betas:
            - 0.9
            - 0.95
        device: mps
        epochs: 10
        grad_clip: 1
        gradient_accumulation_steps: 4
        lr: 0.0001
        micor_batch_size: 4
        total_steps: 100
        weight_decay: 0.01
version:
    value: baseline
