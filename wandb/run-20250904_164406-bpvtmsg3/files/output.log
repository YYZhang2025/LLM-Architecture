[32mModel initialized. Number of parameters: [0m[1;32m27368448[0m
/Users/yuyang/Desktop/Projects/LLM-Architecture/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.
  warnings.warn(warn_msg)
Step 10/100, Loss: 8.8304
Traceback (most recent call last):
  File "/Users/yuyang/Desktop/Projects/LLM-Architecture/train_scripts/train_baseline.py", line 108, in <module>
    train(model_config, train_cfg, run)
  File "/Users/yuyang/Desktop/Projects/LLM-Architecture/train_scripts/train_baseline.py", line 72, in train
    sample_logits, _ = model(input_ids=sample_input_id, attention_mask=None)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yuyang/Desktop/Projects/LLM-Architecture/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yuyang/Desktop/Projects/LLM-Architecture/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yuyang/Desktop/Projects/LLM-Architecture/llm/models/baseline.py", line 89, in forward
    x = self.embedding(input_ids)
        ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yuyang/Desktop/Projects/LLM-Architecture/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yuyang/Desktop/Projects/LLM-Architecture/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yuyang/Desktop/Projects/LLM-Architecture/llm/models/baseline.py", line 33, in forward
    x = self.pos_enc(x)
        ^^^^^^^^^^^^^^^
  File "/Users/yuyang/Desktop/Projects/LLM-Architecture/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1773, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yuyang/Desktop/Projects/LLM-Architecture/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1784, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yuyang/Desktop/Projects/LLM-Architecture/llm/modules/position_encodings/learned_pe.py", line 18, in forward
    x = x + self.encoding[:seq_len, :].unsqueeze(0)
        ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
RuntimeError: The size of tensor a (511) must match the size of tensor b (512) at non-singleton dimension 1
